{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supermarket chain Good Seed would like to explore whether Data Science can help them adhere to alcohol laws by making sure they do not sell alcohol to people underage. You are asked to conduct that evaluation, so as you set to work, keep the following in mind:\n",
    "The shops are equipped with cameras in the checkout area which are triggered when a person is buying alcohol\n",
    "Computer vision methods can be used to determine age of a person from a photo\n",
    "The task then is to build and evaluate a model for verifying people's age\n",
    "To start working on the task, you'll have a set of photographs of people with their ages indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is stored in the `/datasets/faces/` folder, there you can find\n",
    "- The `final_files` folder with 7.6k photos\n",
    "- The `labels.csv` file with labels, with two columns: `file_name` and `real_age`\n",
    "\n",
    "Given the fact that the number of image files is rather high, it is advisable to avoid reading them all at once, which would greatly consume computational resources. We recommend you build a generator with the ImageDataGenerator generator. This method was explained in Chapter 3, Lesson 7 of this course.\n",
    "\n",
    "The label file can be loaded as an usual CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7591 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory='/datasets/faces/final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        seed=12345) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import image\n",
    "\n",
    "#Look at the dataset size.\n",
    "#Explore the age distribution in the dataset.\n",
    "#Print 10-15 photos for different ages on the screen to get an overall impression of the dataset.\n",
    "\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print()\n",
    "print('duplicated elements:',labels.duplicated().sum())\n",
    "print(labels['file_name'])\n",
    "print()\n",
    "print('real age NaNs:',labels[labels['real_age'].isna() == True].size)\n",
    "print('file name NaNs',labels[labels['file_name'].isna() == True].size)\n",
    "labels.hist(bins=100)\n",
    "plt.show()\n",
    "labels.boxplot()\n",
    "plt.show()\n",
    "\n",
    "by_age = labels.pivot_table(index='real_age',values='file_name',aggfunc='count')\n",
    "\n",
    "by_age.plot()\n",
    "\n",
    "by_age.boxplot()\n",
    "\n",
    "#I really shouldn't try to load and show all 7.6k images in the notebook, since it used to be range(len(train_gen_flow.filenames)):\n",
    "for i in range(10):\n",
    "     image, label = train_gen_flow.next()\n",
    "     # display the image from the iterator\n",
    "     for j in range(0,14):\n",
    "        plt.imshow(image[j])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing bad so far. The median is early 20's which is perfect since the legal drinking age is 21.  Outliers are past 60. This is a right skewed graph. A data distribution with additional values on the right is said to skew to the right. This is often called positive skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the necessary functions to train your model on the GPU platform and build a single script containing all of them along with the initialization section.\n",
    "\n",
    "To make this task easier, you can define them in this notebook and run a ready code in the next section to automatically compose the script.\n",
    "\n",
    "The definitions below will be checked by project reviewers as well, so that they can understand how you built the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    It loads the train part of dataset from path\n",
    "    \n",
    "    Remember you still need to load what you need seperately from the path.\n",
    "    Use flow_from_dataframe instead of flow_from_directory.\n",
    "    The path is /datasets/faces/ and we don't need the / at the end for folders.\n",
    "    Remember to add the subsets to split it!\n",
    "    \n",
    "    Reminder to me: horizontal_flip should be used as an argument when ImageDataGenerator is initialized, not as argument of flow_from_dataframe method\n",
    "    Any augmentations should only be applied to the training data, so horizontal flip shouldn't be applied in load_test function (otherwise we can end up with an overly optimistic estimate of the model's generalization performance, and the goal of augmentations is just to create more traning data basically for free)\n",
    "    \"\"\"\n",
    "    \n",
    "    # place your code here\n",
    "    labels = pd.read_csv(path+'labels.csv')                                                     \n",
    "    train_datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.25, horizontal_flip=True)  \n",
    "    train_datagen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe = labels,\n",
    "        directory = path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        seed=42)\n",
    "    return train_datagen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    It loads the validation/test part of dataset from path\n",
    "    Reminder to me:In load_test it should be subset='validation', otherwise we're evaluating the model on the same data it was trained on :)\n",
    "    \"\"\"\n",
    "    \n",
    "    # place your code here\n",
    "    labels = pd.read_csv(path+'labels.csv')                                                     \n",
    "    train_datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.25)  \n",
    "    train_datagen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe = labels,\n",
    "        directory = path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=42)\n",
    "    return test_datagen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    It defines the model\n",
    "    As this is the regression task, you may want to use either the MSE loss function or the MAE one. However, neural networks with the MSE loss function are typically trained faster than with the MAE ones. In either of the cases, MAE remains the evaluation metric.\n",
    "    input_shape is gotten from the parameter not inputed yourself as (150, 150, 3)\n",
    "    \"\"\"\n",
    "    \n",
    "    # place your code here\n",
    "    backbone = ResNet50(input_shape= input_shape,\n",
    "                    weights='imagenet', \n",
    "                    include_top= False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    optimizer = Adam(lr=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error',metrics=['mae']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=None, epochs=10,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Trains the model given the parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    # place your code here\n",
    "    \n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    "    model.fit(train_data, \n",
    "              validation_data= test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Script to Run on the GPU Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given you've defined the necessary functions you can compose a script for the GPU platform, download it via the \"File|Open...\" menu, and to upload it later for running on the GPU platform.\n",
    "\n",
    "N.B.: The script should include the initialization section as well. An example of this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a script to run on the GPU platform\n",
    "\n",
    "init_str = \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "\n",
    "with open('run_model_on_gpu.py', 'w') as f:\n",
    "    \n",
    "    f.write(init_str)\n",
    "    f.write('\\n\\n')\n",
    "        \n",
    "    for fn_name in [load_train, load_test, create_model, train_model]:\n",
    "        \n",
    "        src = inspect.getsource(fn_name)\n",
    "        f.write(src)\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place the output from the GPU platform as an Markdown cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022-11-01 04:00:02.256853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
    "2022-11-01 04:00:02.380907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
    "Using TensorFlow backend.\n",
    "Found 5694 validated image filenames.\n",
    "Found 1897 validated image filenames.\n",
    "2022-11-01 04:00:07.287929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2022-11-01 04:00:07.399108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.399329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-11-01 04:00:07.399382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:07.399419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:07.494208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-11-01 04:00:07.513218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-11-01 04:00:07.687024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-11-01 04:00:07.707176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-11-01 04:00:07.707250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-11-01 04:00:07.707408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.707700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.707870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-11-01 04:00:07.708315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2022-11-01 04:00:07.751700: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300015000 Hz\n",
    "2022-11-01 04:00:07.754005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f620d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2022-11-01 04:00:07.754046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2022-11-01 04:00:07.923526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.923852: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2da0720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "2022-11-01 04:00:07.923876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
    "2022-11-01 04:00:07.924134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-11-01 04:00:07.924386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:07.924405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:07.924445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-11-01 04:00:07.924461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-11-01 04:00:07.924476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-11-01 04:00:07.924490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-11-01 04:00:07.924500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-11-01 04:00:07.924586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-11-01 04:00:07.926968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:10.123127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2022-11-01 04:00:10.123179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
    "2022-11-01 04:00:10.123190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
    "2022-11-01 04:00:10.125037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:10.125320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:10.125492: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
    "2022-11-01 04:00:10.125547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14988 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\n",
    "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "    8192/94765736 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    " 8871936/94765736 [=>............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "18292736/94765736 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "29827072/94765736 [========>.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "37756928/94765736 [==========>...................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "49274880/94765736 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "52871168/94765736 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "58793984/94765736 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "66363392/94765736 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "75505664/94765736 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "87220224/94765736 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "94773248/94765736 [==============================] - 1s 0us/step\n",
    "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "Train for 178 steps, validate for 60 steps\n",
    "Epoch 1/10\n",
    "2022-11-01 04:00:28.643427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:29.831296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "178/178 - 63s - loss: 203.1177 - mae: 10.6800 - val_loss: 358.4354 - val_mae: 14.0400\n",
    "Epoch 2/10\n",
    "178/178 - 39s - loss: 113.0923 - mae: 8.0743 - val_loss: 525.2079 - val_mae: 17.7680\n",
    "Epoch 3/10\n",
    "178/178 - 39s - loss: 88.4932 - mae: 7.1680 - val_loss: 423.2995 - val_mae: 15.3790\n",
    "Epoch 4/10\n",
    "178/178 - 39s - loss: 74.6991 - mae: 6.5607 - val_loss: 170.1841 - val_mae: 10.1973\n",
    "Epoch 5/10\n",
    "178/178 - 40s - loss: 60.3922 - mae: 5.9806 - val_loss: 159.6877 - val_mae: 10.1872\n",
    "Epoch 6/10\n",
    "178/178 - 40s - loss: 50.2668 - mae: 5.3520 - val_loss: 84.8826 - val_mae: 6.9760\n",
    "Epoch 7/10\n",
    "Epoch 8/10\n",
    "178/178 - 39s - loss: 44.3392 - mae: 5.0997 - val_loss: 91.1241 - val_mae: 7.1879\n",
    "178/178 - 39s - loss: 37.8437 - mae: 4.7105 - val_loss: 100.4241 - val_mae: 7.7159\n",
    "Epoch 9/10\n",
    "178/178 - 39s - loss: 31.0166 - mae: 4.2301 - val_loss: 81.8848 - val_mae: 6.6861\n",
    "Epoch 10/10\n",
    "178/178 - 39s - loss: 25.5607 - mae: 3.8835 - val_loss: 83.7814 - val_mae: 6.7650\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "60/60 - 10s - loss: 83.7814 - mae: 6.7650\n",
    "Test MAE: 6.7650\n",
    "2022-11-01 04:00:02.256853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6\n",
    "2022-11-01 04:00:02.380907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6\n",
    "Using TensorFlow backend.\n",
    "Found 5694 validated image filenames.\n",
    "Found 1897 validated image filenames.\n",
    "2022-11-01 04:00:07.287929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
    "2022-11-01 04:00:07.399108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.399329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-11-01 04:00:07.399382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:07.399419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:07.494208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-11-01 04:00:07.513218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-11-01 04:00:07.687024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-11-01 04:00:07.707176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-11-01 04:00:07.707250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-11-01 04:00:07.707408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.707700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.707870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-11-01 04:00:07.708315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2022-11-01 04:00:07.751700: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300015000 Hz\n",
    "2022-11-01 04:00:07.754005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f620d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2022-11-01 04:00:07.754046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "2022-11-01 04:00:07.923526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.923852: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2da0720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
    "2022-11-01 04:00:07.923876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
    "2022-11-01 04:00:07.924134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
    "pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
    "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
    "2022-11-01 04:00:07.924386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:07.924405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:07.924445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
    "2022-11-01 04:00:07.924461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
    "2022-11-01 04:00:07.924476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
    "2022-11-01 04:00:07.924490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
    "2022-11-01 04:00:07.924500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "2022-11-01 04:00:07.924586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:07.924964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
    "2022-11-01 04:00:07.926968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
    "2022-11-01 04:00:10.123127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2022-11-01 04:00:10.123179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
    "2022-11-01 04:00:10.123190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
    "2022-11-01 04:00:10.125037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:10.125320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2022-11-01 04:00:10.125492: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
    "2022-11-01 04:00:10.125547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14988 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\n",
    "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "    8192/94765736 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    " 8871936/94765736 [=>............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "18292736/94765736 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "29827072/94765736 [========>.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "37756928/94765736 [==========>...................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "49274880/94765736 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "52871168/94765736 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "58793984/94765736 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "66363392/94765736 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "75505664/94765736 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "87220224/94765736 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "94773248/94765736 [==============================] - 1s 0us/step\n",
    "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "Train for 178 steps, validate for 60 steps\n",
    "Epoch 1/10\n",
    "2022-11-01 04:00:28.643427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2022-11-01 04:00:29.831296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "178/178 - 63s - loss: 203.1177 - mae: 10.6800 - val_loss: 358.4354 - val_mae: 14.0400\n",
    "Epoch 2/10\n",
    "178/178 - 39s - loss: 113.0923 - mae: 8.0743 - val_loss: 525.2079 - val_mae: 17.7680\n",
    "Epoch 3/10\n",
    "178/178 - 39s - loss: 88.4932 - mae: 7.1680 - val_loss: 423.2995 - val_mae: 15.3790\n",
    "Epoch 4/10\n",
    "178/178 - 39s - loss: 74.6991 - mae: 6.5607 - val_loss: 170.1841 - val_mae: 10.1973\n",
    "Epoch 5/10\n",
    "178/178 - 40s - loss: 60.3922 - mae: 5.9806 - val_loss: 159.6877 - val_mae: 10.1872\n",
    "Epoch 6/10\n",
    "178/178 - 40s - loss: 50.2668 - mae: 5.3520 - val_loss: 84.8826 - val_mae: 6.9760\n",
    "Epoch 7/10\n",
    "178/178 - 39s - loss: 44.3392 - mae: 5.0997 - val_loss: 91.1241 - val_mae: 7.1879\n",
    "Epoch 8/10\n",
    "178/178 - 39s - loss: 37.8437 - mae: 4.7105 - val_loss: 100.4241 - val_mae: 7.7159\n",
    "Epoch 9/10\n",
    "178/178 - 39s - loss: 31.0166 - mae: 4.2301 - val_loss: 81.8848 - val_mae: 6.6861\n",
    "Epoch 10/10\n",
    "178/178 - 39s - loss: 25.5607 - mae: 3.8835 - val_loss: 83.7814 - val_mae: 6.7650\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "60/60 - 10s - loss: 83.7814 - mae: 6.7650\n",
    "Test MAE: 6.7650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a neural network model requires a lot of computing power so it needs to be done on the GPU platform (the files are also on the platform). Results can be captured by printing the model's output. The output was saved and returned to me.\n",
    "\n",
    "I used a pre-trained model for the task, specifically, one which was pre-trained on a large dataset of images called imagenet. You can check the content of that dataset at: http://www.image-net.org/. This is not a dataset that's strictly about faces, so the pre-trained weights might not work the best for faces. However, it is somewhat valid to use this dataset for face classification because the imagenet dataset is mostly about natural objects and contains a subset of faces too. By setting the 'weights' parameter to 'imagenet,' we're able to load weights of this pre-trained neural network for the ResNet50 architecture.\n",
    "By the way, there are more than 23 million trainable parameters in the ResNet50 model. This is the reason why using it without a GPU platform would cause a very, very long wait time for a model to be trained, even if it has been pre-trained.\n",
    "\n",
    "In one article about this dataset I am working with (http://people.ee.ethz.ch/~timofter/publications/Agustsson-FG-2017.pdf), the lowest MAE value reached is 5.4. Meaning, if you get MAE less than 7, it would be a great result! \n",
    "\n",
    "With an MAE less than 7 (6.7650), the model is more than enough to detect underage people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X]  Notebook was opened\n",
    "- [X]  The code is error free\n",
    "- [X]  The cells with code have been arranged by order of execution\n",
    "- [X]  The exploratory data analysis has been performed\n",
    "- [X]  The results of the exploratory data analysis are presented in the final notebook\n",
    "- [X]  The model's MAE score is not higher than 8\n",
    "- [X]  The model training code has been copied to the final notebook\n",
    "- [X]  The model training output has been copied to the final notebook\n",
    "- [X]  The findings have been provided based on the results of the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
